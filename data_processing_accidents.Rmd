---
title: "D1"
output: html_document
date: "2024-02-15"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##imports
```{r}
library(dplyr)
```

##load files
```{r}
accidents <- read.csv("2022-data/2022_accidents_gu_bcn.csv")

persones <- read.csv("2022-data/2022_accidents_persones_gu_bcn.csv")
```


##Get File names and compare them

```{r}
# Obtener los nombres de las columnas de cada tabla
colnames_accidents <- colnames(accidents)
colnames_persones <- colnames(persones)

# Encontrar los nombres de columna comunes a todas las tablas
common_names <- Reduce(intersect, list(colnames_accidents, colnames_persones))

# Nombres de columna únicos en cada tabla
unique_names_accidents <- setdiff(colnames_accidents, common_names)
unique_names_persones <- setdiff(colnames_persones, common_names)
```

# Here we print the results in order to visualize the different columns
```{r}
print("Nombres de columna comunes en las tres tablas:")
print(common_names)
```

```{r}
print("Nombres de columna únicos en accidents:")
print(unique_names_accidents)
```

```{r}
print("Nombres de columna únicos en persones:")
print(unique_names_persones)
```



#Here we are pre merging the data in order to get the colums with the same value but different name
```{r}
key_column <- "Numero_expedient"

# Fusiona les taules
merged_data <- merge(accidents, persones, by = key_column)
# Imprimeix les primeres files del resultat
head(merged_data)

```
##Here we are detecting duplicates. We'll keep them for later
```{r}
# Función para encontrar columnas con los mismos valores
find_duplicate_columns <- function(dataframe) {
  duplicate_columns <- vector()
  dataframe <- as.data.frame(lapply(dataframe, as.character), stringsAsFactors = FALSE)
  for (i in 1:(ncol(dataframe) - 1)) {
    for (j in (i + 1):ncol(dataframe)) {
      if (all(dataframe[, i] == dataframe[, j])) {
        duplicate_columns <- c(duplicate_columns, names(dataframe)[i])
        break
      }
    }
  }
  return(duplicate_columns)
}

# Detectar columnas con los mismos valores
columnas_con_valores_iguales <- find_duplicate_columns(merged_data)

# Imprimir el resultado
print("Columnas con los mismos valores:")
print(columnas_con_valores_iguales)

```



##THIS HAS TO CHANGE
What i'm doing here is removing the colums of persones and vehicles that already exist in accidents. But this is not right as there are colums with the same name that have different values (We can see this executing line 97)
```{r}
repetits <- setdiff(common_names, "Numero_expedient")
persones <- persones %>%
  select(-any_of(repetits))
```

#Now we are merging the 2 filtered datasets. With this we get a dataset that only contains columns with different names. BUT there is still repeated columns that have different names. 
```{r}
key_column <- "Numero_expedient"

# Fusiona les taules
merged_data <- merge(accidents, persones, by = key_column)
# Imprimeix les primeres files del resultat
head(merged_data)



```

##Now we are deleting the repeated columns.
```{r}
# Eliminar las columnas con los mismos valores
merged_data <- merged_data[, !(names(merged_data) %in% columnas_con_valores_iguales)]

```


#In order to answer the exercice here we are obtaining the number of categoric and numeric vars.
```{r}
# Número de variables categóricas
num_categoricas <- sum(sapply(merged_data, is.factor) | sapply(merged_data, is.character))

# Número de variables cuantitativas
num_cuantitativas <- sum(sapply(merged_data, is.numeric))

# Imprimir los resultados
print(paste("Número de variables categóricas:", num_categoricas))
print(paste("Número de variables cuantitativas:", num_cuantitativas))
```
##As we can see there are 18 categoric and 16 numeric. But one of the categoric is MALE/FEMALE and that is a binary var. In order to fullfill the dataset requirements we need one more binary bar. We've decided that the binary bar will be if it is a Bicicle accident or not. 

```{r}
# Crear la nova columna
merged_data <- merged_data %>%
  mutate(Accident_en_bicicleta = ifelse(Desc_Tipus_vehicle_implicat == "Bicicleta", 1, 0))
```

### Esborrem la ultima columna problemàtica
```{r}
# Assuming merged_data is your data frame
columns_to_remove <- c("Num_postal_caption")
merged_data <- merged_data[ , !(names(merged_data) %in% columns_to_remove)]
```

##Renaming de les columnes
```{r}
# List of new column names
new_column_names <- c("nExp", "cDis", "nDis", "cBar", "nBar", "cCar", "nCar", "dSet", "any", "nMes", "mes", "dia", "hora", "torn", "causa", "morts", "lesLl", "lesGr", "vict", "vehi", "UTMX", "UTMY", "long", "lat", "nPos", "dTVehImp", "sexe", "edat", "dTPers", "dLlAtrVia", "dMotDesVia", "dMotDespCon", "dVict", "accbici")

# Assuming merged_data is your dataframe
names(merged_data) <- new_column_names

```

#Generar csv
```{r}

# Generem el csv
attributes(merged_data)
write.csv(merged_data, "merged_data.csv", row.names = FALSE)

```

###PCA
```{r}
library(tidyverse) # For data manipulation
library(factoextra) # For easy visualization of PCA results

merged_data$edat <- as.numeric(as.character(merged_data$edat))
# Selecting only the relevant columns for PCA
pca_data <- merged_data %>%
  select(morts, lesLl, lesGr, vict, vehi, edat) %>%
  na.omit() # Removing rows with any missing values

# Standardizing the data: Important for PCA to treat all variables equally
pca_data_scaled <- scale(pca_data)

# Running PCA
pca_result <- prcomp(pca_data_scaled, center = TRUE, scale. = TRUE)

# Summary of PCA result
summary(pca_result)

# Plotting the variance explained by each principal component
fviz_eig(pca_result)

# For a more detailed view, including the contributions of original variables to the principal components:
fviz_pca_var(pca_result, col.var = "cos2", 
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE) # Cos2 shows the quality of representation

```

#mca

```{r}
install.packages("FactoMineR")
install.packages("factoextra")
library(FactoMineR)
library(factoextra)
# Assuming merged_data is your data frame and contains the categorical variables for MCA
# Let's say cDis, nDis, causa, sexe, dTVehImp are the columns you want to include in MCA

# Selecting only the relevant categorical columns for MCA
mca_data <- merged_data %>%
  select(nExp, nDis, nBar, nCar, dSet,  causa, sexe, dTVehImp) %>%
  na.omit()  # Make sure to handle NAs according to your specific needs

# Performing MCA
mca_results <- MCA(mca_data, graph = FALSE)

# Summary of the MCA results
summary(mca_results)

# Plotting the results
# Visualize dimensions 1 and 2
fviz_mca_biplot(mca_results, repel = TRUE)

# For individual points
fviz_mca_ind(mca_results, col.ind = "cos2", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), repel = TRUE)

# For variable categories
fviz_mca_var(mca_results, col.var = "cos2", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), repel = TRUE)

```

##Count the number of expedients
```{r}
 # Contar el número de expedientes únicos
num_expedients_diferents <- merged_data %>%
  distinct(Numero_expedient) %>%
  nrow()

# Imprimir el resultado
print(num_expedients_diferents)
```
#Missing data
```{r}
missing_counts <- sapply(merged_data, function(x) sum(x == "Desconegut", na.rm = TRUE))
# Calculate total number of rows
total_rows <- nrow(merged_data)

# Calculate percentage of missing values per column
missing_percentages <- (missing_counts / total_rows) * 100
# Combine results into a dataframe
missing_data_summary <- data.frame(
  Column = names(merged_data),
  Missing_Count = missing_counts,
  Missing_Percentage = missing_percentages
)

# Print the summary
print(missing_data_summary)

#Get the csv
write.csv(missing_data_summary, "missing_data_summary.csv", row.names = FALSE)


```
```{r}
# Missing data plot
missing_per_individual <- rowSums(is.na(merged_data) | merged_data == "Desconegut")
frequency_values <- table(missing_per_individual)

print(frequency_values)

barplot(table(missing_per_individual),
        main = "Frecuencia de valores faltantes por individuo",
        xlab = "Número de valores faltantes por individuo",
        ylab = "Frecuencia",
        col = "skyblue")



```



```{r}
# Count total number of unknown values
total_unknown <- sum(merged_data == "Desconegut", na.rm = TRUE)

# Calculate total number of cells in the dataframe
total_cells <- nrow(merged_data) * ncol(merged_data)

# Calculate percentage of unknown values
unknown_percentage <- (total_unknown / total_cells) * 100

# Print the results
print(paste("Total number of unknown values:", total_unknown))
print(paste("Percentage of unknown values:", unknown_percentage, "%"))
```

